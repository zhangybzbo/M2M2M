No attention, no weight decay, pre-trained unfixed
Embedding_size = 200
Hidden_size = 200
Learning_rate = 0.0005
Epoch = 100
Batch_size = 128
1266 different words, 181 different codes
Fold 0: 1655 training data, 504 testing data
[fold 0 epoch 9] training loss: 3.3513, testing: 159 correct, 0.3155 accuracy
[fold 0 epoch 19] training loss: 2.6705, testing: 204 correct, 0.4048 accuracy
[fold 0 epoch 29] training loss: 2.2694, testing: 228 correct, 0.4524 accuracy
[fold 0 epoch 39] training loss: 1.8828, testing: 262 correct, 0.5198 accuracy
[fold 0 epoch 49] training loss: 1.5399, testing: 281 correct, 0.5575 accuracy
[fold 0 epoch 59] training loss: 1.2590, testing: 301 correct, 0.5972 accuracy
[fold 0 epoch 69] training loss: 0.9986, testing: 302 correct, 0.5992 accuracy
[fold 0 epoch 79] training loss: 0.8050, testing: 311 correct, 0.6171 accuracy
[fold 0 epoch 89] training loss: 0.6327, testing: 326 correct, 0.6468 accuracy
[fold 0 epoch 99] training loss: 0.5248, testing: 324 correct, 0.6429 accuracy
Fold 1: 1700 training data, 459 testing data
[fold 1 epoch 9] training loss: 3.4283, testing: 154 correct, 0.3355 accuracy
[fold 1 epoch 19] training loss: 2.7949, testing: 198 correct, 0.4314 accuracy
[fold 1 epoch 29] training loss: 2.3469, testing: 231 correct, 0.5033 accuracy
[fold 1 epoch 39] training loss: 1.9617, testing: 250 correct, 0.5447 accuracy
[fold 1 epoch 49] training loss: 1.5025, testing: 277 correct, 0.6035 accuracy
[fold 1 epoch 59] training loss: 1.2035, testing: 297 correct, 0.6471 accuracy
[fold 1 epoch 69] training loss: 0.9381, testing: 318 correct, 0.6928 accuracy
[fold 1 epoch 79] training loss: 0.6961, testing: 309 correct, 0.6732 accuracy
[fold 1 epoch 89] training loss: 0.5245, testing: 312 correct, 0.6797 accuracy
[fold 1 epoch 99] training loss: 0.3852, testing: 312 correct, 0.6797 accuracy
Fold 2: 1735 training data, 424 testing data
[fold 2 epoch 9] training loss: 3.4038, testing: 166 correct, 0.3915 accuracy
[fold 2 epoch 19] training loss: 2.8319, testing: 193 correct, 0.4552 accuracy
[fold 2 epoch 29] training loss: 2.3021, testing: 216 correct, 0.5094 accuracy
[fold 2 epoch 39] training loss: 1.9763, testing: 237 correct, 0.5590 accuracy
[fold 2 epoch 49] training loss: 1.6138, testing: 256 correct, 0.6038 accuracy
[fold 2 epoch 59] training loss: 1.2769, testing: 267 correct, 0.6297 accuracy
[fold 2 epoch 69] training loss: 0.9921, testing: 277 correct, 0.6533 accuracy
[fold 2 epoch 79] training loss: 0.7451, testing: 286 correct, 0.6745 accuracy
[fold 2 epoch 89] training loss: 0.6066, testing: 275 correct, 0.6486 accuracy
[fold 2 epoch 99] training loss: 0.4954, testing: 272 correct, 0.6415 accuracy
Fold 3: 1762 training data, 397 testing data
[fold 3 epoch 9] training loss: 3.4356, testing: 131 correct, 0.3300 accuracy
[fold 3 epoch 19] training loss: 2.7936, testing: 172 correct, 0.4332 accuracy
[fold 3 epoch 29] training loss: 2.3157, testing: 211 correct, 0.5315 accuracy
[fold 3 epoch 39] training loss: 1.8805, testing: 230 correct, 0.5793 accuracy
[fold 3 epoch 49] training loss: 1.5758, testing: 247 correct, 0.6222 accuracy
[fold 3 epoch 59] training loss: 1.2568, testing: 268 correct, 0.6751 accuracy
[fold 3 epoch 69] training loss: 1.0109, testing: 268 correct, 0.6751 accuracy
[fold 3 epoch 79] training loss: 0.7646, testing: 265 correct, 0.6675 accuracy
[fold 3 epoch 89] training loss: 0.6464, testing: 278 correct, 0.7003 accuracy
[fold 3 epoch 99] training loss: 0.5020, testing: 277 correct, 0.6977 accuracy
Fold 4: 1784 training data, 375 testing data
[fold 4 epoch 9] training loss: 3.5750, testing: 89 correct, 0.2373 accuracy
[fold 4 epoch 19] training loss: 2.9189, testing: 108 correct, 0.2880 accuracy
[fold 4 epoch 29] training loss: 2.3536, testing: 143 correct, 0.3813 accuracy
[fold 4 epoch 39] training loss: 1.9250, testing: 197 correct, 0.5253 accuracy
[fold 4 epoch 49] training loss: 1.5663, testing: 211 correct, 0.5627 accuracy
[fold 4 epoch 59] training loss: 1.2694, testing: 225 correct, 0.6000 accuracy
[fold 4 epoch 69] training loss: 0.9517, testing: 221 correct, 0.5893 accuracy
[fold 4 epoch 79] training loss: 0.7684, testing: 216 correct, 0.5760 accuracy
[fold 4 epoch 89] training loss: 0.5473, testing: 192 correct, 0.5120 accuracy
[fold 4 epoch 99] training loss: 0.4502, testing: 200 correct, 0.5333 accuracy
finial accuracy: 0.6390


With self attention, with weight decay, with lr decay, pre-train fixed
pre-train unfixed: 0.6639
Embedding_size = 200
Hidden_size = 200
Learning_rate = 0.0005
Weight_decay = 0.0015
LR_decay = 0.5
Epoch = 150
LR_decay_epoch = 75
Batch_size = 128
1266 different words, 181 different codes
Fold 0: 1655 training data, 504 testing data
[fold 0 epoch 9] training loss: 3.0397, testing: 184 correct, 0.3651 accuracy
[fold 0 epoch 19] training loss: 2.4700, testing: 222 correct, 0.4405 accuracy
[fold 0 epoch 29] training loss: 1.9846, testing: 252 correct, 0.5000 accuracy
[fold 0 epoch 39] training loss: 1.6273, testing: 273 correct, 0.5417 accuracy
[fold 0 epoch 49] training loss: 1.3323, testing: 287 correct, 0.5694 accuracy
[fold 0 epoch 59] training loss: 1.1164, testing: 310 correct, 0.6151 accuracy
[fold 0 epoch 69] training loss: 0.9159, testing: 318 correct, 0.6310 accuracy
learning rate decay!
[fold 0 epoch 79] training loss: 0.7513, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 89] training loss: 0.6973, testing: 315 correct, 0.6250 accuracy
[fold 0 epoch 99] training loss: 0.6460, testing: 309 correct, 0.6131 accuracy
[fold 0 epoch 109] training loss: 0.5927, testing: 317 correct, 0.6290 accuracy
[fold 0 epoch 119] training loss: 0.5545, testing: 317 correct, 0.6290 accuracy
[fold 0 epoch 129] training loss: 0.5071, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 139] training loss: 0.5191, testing: 321 correct, 0.6369 accuracy
[fold 0 epoch 149] training loss: 0.4526, testing: 315 correct, 0.6250 accuracy
learning rate decay!
Fold 1: 1700 training data, 459 testing data
[fold 1 epoch 9] training loss: 3.2686, testing: 186 correct, 0.4052 accuracy
[fold 1 epoch 19] training loss: 2.6638, testing: 243 correct, 0.5294 accuracy
[fold 1 epoch 29] training loss: 2.2350, testing: 276 correct, 0.6013 accuracy
[fold 1 epoch 39] training loss: 1.8426, testing: 301 correct, 0.6558 accuracy
[fold 1 epoch 49] training loss: 1.5390, testing: 313 correct, 0.6819 accuracy
[fold 1 epoch 59] training loss: 1.2634, testing: 319 correct, 0.6950 accuracy
[fold 1 epoch 69] training loss: 1.0266, testing: 317 correct, 0.6906 accuracy
learning rate decay!
[fold 1 epoch 79] training loss: 0.8707, testing: 319 correct, 0.6950 accuracy
[fold 1 epoch 89] training loss: 0.7924, testing: 322 correct, 0.7015 accuracy
[fold 1 epoch 99] training loss: 0.7046, testing: 322 correct, 0.7015 accuracy
[fold 1 epoch 109] training loss: 0.6635, testing: 325 correct, 0.7081 accuracy
[fold 1 epoch 119] training loss: 0.6253, testing: 321 correct, 0.6993 accuracy
[fold 1 epoch 129] training loss: 0.5824, testing: 321 correct, 0.6993 accuracy
[fold 1 epoch 139] training loss: 0.5055, testing: 326 correct, 0.7102 accuracy
[fold 1 epoch 149] training loss: 0.5107, testing: 327 correct, 0.7124 accuracy
learning rate decay!
Fold 2: 1735 training data, 424 testing data
[fold 2 epoch 9] training loss: 3.1823, testing: 198 correct, 0.4670 accuracy
[fold 2 epoch 19] training loss: 2.5435, testing: 246 correct, 0.5802 accuracy
[fold 2 epoch 29] training loss: 2.0799, testing: 269 correct, 0.6344 accuracy
[fold 2 epoch 39] training loss: 1.7373, testing: 279 correct, 0.6580 accuracy
[fold 2 epoch 49] training loss: 1.3928, testing: 284 correct, 0.6698 accuracy
[fold 2 epoch 59] training loss: 1.0860, testing: 287 correct, 0.6769 accuracy
[fold 2 epoch 69] training loss: 0.8767, testing: 284 correct, 0.6698 accuracy
learning rate decay!
[fold 2 epoch 79] training loss: 0.6942, testing: 290 correct, 0.6840 accuracy
[fold 2 epoch 89] training loss: 0.6706, testing: 294 correct, 0.6934 accuracy
[fold 2 epoch 99] training loss: 0.6265, testing: 292 correct, 0.6887 accuracy
[fold 2 epoch 109] training loss: 0.5902, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 119] training loss: 0.5268, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 129] training loss: 0.4802, testing: 292 correct, 0.6887 accuracy
[fold 2 epoch 139] training loss: 0.4672, testing: 294 correct, 0.6934 accuracy
[fold 2 epoch 149] training loss: 0.4178, testing: 292 correct, 0.6887 accuracy
learning rate decay!
Fold 3: 1762 training data, 397 testing data
[fold 3 epoch 9] training loss: 3.0857, testing: 178 correct, 0.4484 accuracy
[fold 3 epoch 19] training loss: 2.5057, testing: 217 correct, 0.5466 accuracy
[fold 3 epoch 29] training loss: 2.1108, testing: 240 correct, 0.6045 accuracy
[fold 3 epoch 39] training loss: 1.7049, testing: 255 correct, 0.6423 accuracy
[fold 3 epoch 49] training loss: 1.4133, testing: 269 correct, 0.6776 accuracy
[fold 3 epoch 59] training loss: 1.1815, testing: 276 correct, 0.6952 accuracy
[fold 3 epoch 69] training loss: 0.9534, testing: 280 correct, 0.7053 accuracy
learning rate decay!
[fold 3 epoch 79] training loss: 0.8272, testing: 282 correct, 0.7103 accuracy
[fold 3 epoch 89] training loss: 0.7479, testing: 287 correct, 0.7229 accuracy
[fold 3 epoch 99] training loss: 0.6971, testing: 286 correct, 0.7204 accuracy
[fold 3 epoch 109] training loss: 0.6336, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 119] training loss: 0.5724, testing: 284 correct, 0.7154 accuracy
[fold 3 epoch 129] training loss: 0.5193, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 139] training loss: 0.5044, testing: 286 correct, 0.7204 accuracy
[fold 3 epoch 149] training loss: 0.4541, testing: 285 correct, 0.7179 accuracy
learning rate decay!
Fold 4: 1784 training data, 375 testing data
[fold 4 epoch 9] training loss: 3.1467, testing: 158 correct, 0.4213 accuracy
[fold 4 epoch 19] training loss: 2.5232, testing: 195 correct, 0.5200 accuracy
[fold 4 epoch 29] training loss: 2.0401, testing: 216 correct, 0.5760 accuracy
[fold 4 epoch 39] training loss: 1.6456, testing: 234 correct, 0.6240 accuracy
[fold 4 epoch 49] training loss: 1.3100, testing: 228 correct, 0.6080 accuracy
[fold 4 epoch 59] training loss: 1.0469, testing: 231 correct, 0.6160 accuracy
[fold 4 epoch 69] training loss: 0.8721, testing: 230 correct, 0.6133 accuracy
learning rate decay!
[fold 4 epoch 79] training loss: 0.7517, testing: 232 correct, 0.6187 accuracy
[fold 4 epoch 89] training loss: 0.6748, testing: 240 correct, 0.6400 accuracy
[fold 4 epoch 99] training loss: 0.6511, testing: 239 correct, 0.6373 accuracy
[fold 4 epoch 109] training loss: 0.5702, testing: 238 correct, 0.6347 accuracy
[fold 4 epoch 119] training loss: 0.5413, testing: 235 correct, 0.6267 accuracy
[fold 4 epoch 129] training loss: 0.4620, testing: 238 correct, 0.6347 accuracy
[fold 4 epoch 139] training loss: 0.4666, testing: 233 correct, 0.6213 accuracy
[fold 4 epoch 149] training loss: 0.4290, testing: 237 correct, 0.6320 accuracy
learning rate decay!
finial accuracy: 0.6752


Last hidden state + attention, with weight decay, with lr decay, pre-train fixed
pre-train unfixed: 0.6055
Max_seq_len = 35
Embedding_size = 200
Hidden_size = 200
Inner_hid_size = 2048
D_k = 64
D_v = 64
Learning_rate = 0.0005
Weight_decay = 0.0015
LR_decay = 0.5
Epoch = 150
LR_decay_epoch = 75
Batch_size = 128
1266 different words, 181 different codes
Fold 0: 1655 training data, 504 testing data
[fold 0 epoch 9] training loss: 3.3013, testing: 200 correct, 0.3968 accuracy
[fold 0 epoch 19] training loss: 2.1742, testing: 272 correct, 0.5397 accuracy
[fold 0 epoch 29] training loss: 1.7176, testing: 284 correct, 0.5635 accuracy
[fold 0 epoch 39] training loss: 1.4613, testing: 287 correct, 0.5694 accuracy
[fold 0 epoch 49] training loss: 1.2573, testing: 292 correct, 0.5794 accuracy
[fold 0 epoch 59] training loss: 1.0823, testing: 294 correct, 0.5833 accuracy
[fold 0 epoch 69] training loss: 0.9754, testing: 286 correct, 0.5675 accuracy
learning rate decay!
[fold 0 epoch 79] training loss: 0.8206, testing: 292 correct, 0.5794 accuracy
[fold 0 epoch 89] training loss: 0.7545, testing: 296 correct, 0.5873 accuracy
[fold 0 epoch 99] training loss: 0.6914, testing: 296 correct, 0.5873 accuracy
[fold 0 epoch 109] training loss: 0.6748, testing: 300 correct, 0.5952 accuracy
[fold 0 epoch 119] training loss: 0.6242, testing: 290 correct, 0.5754 accuracy
[fold 0 epoch 129] training loss: 0.6034, testing: 298 correct, 0.5913 accuracy
[fold 0 epoch 139] training loss: 0.5364, testing: 304 correct, 0.6032 accuracy
[fold 0 epoch 149] training loss: 0.5213, testing: 294 correct, 0.5833 accuracy
learning rate decay!
Fold 1: 1700 training data, 459 testing data
[fold 1 epoch 9] training loss: 3.1688, testing: 229 correct, 0.4989 accuracy
[fold 1 epoch 19] training loss: 2.1756, testing: 280 correct, 0.6100 accuracy
[fold 1 epoch 29] training loss: 1.6924, testing: 285 correct, 0.6209 accuracy
[fold 1 epoch 39] training loss: 1.4000, testing: 287 correct, 0.6253 accuracy
[fold 1 epoch 49] training loss: 1.2418, testing: 304 correct, 0.6623 accuracy
[fold 1 epoch 59] training loss: 1.0024, testing: 300 correct, 0.6536 accuracy
[fold 1 epoch 69] training loss: 0.8334, testing: 307 correct, 0.6688 accuracy
learning rate decay!
[fold 1 epoch 79] training loss: 0.7765, testing: 301 correct, 0.6558 accuracy
[fold 1 epoch 89] training loss: 0.7023, testing: 301 correct, 0.6558 accuracy
[fold 1 epoch 99] training loss: 0.6320, testing: 301 correct, 0.6558 accuracy
[fold 1 epoch 109] training loss: 0.5984, testing: 306 correct, 0.6667 accuracy
[fold 1 epoch 119] training loss: 0.5904, testing: 301 correct, 0.6558 accuracy
[fold 1 epoch 129] training loss: 0.5095, testing: 303 correct, 0.6601 accuracy
[fold 1 epoch 139] training loss: 0.4915, testing: 304 correct, 0.6623 accuracy
[fold 1 epoch 149] training loss: 0.4569, testing: 300 correct, 0.6536 accuracy
learning rate decay!
Fold 2: 1735 training data, 424 testing data
[fold 2 epoch 9] training loss: 3.0658, testing: 214 correct, 0.5047 accuracy
[fold 2 epoch 19] training loss: 1.9557, testing: 258 correct, 0.6085 accuracy
[fold 2 epoch 29] training loss: 1.5156, testing: 270 correct, 0.6368 accuracy
[fold 2 epoch 39] training loss: 1.2074, testing: 281 correct, 0.6627 accuracy
[fold 2 epoch 49] training loss: 1.0620, testing: 283 correct, 0.6675 accuracy
[fold 2 epoch 59] training loss: 0.8484, testing: 285 correct, 0.6722 accuracy
[fold 2 epoch 69] training loss: 0.7349, testing: 288 correct, 0.6792 accuracy
learning rate decay!
[fold 2 epoch 79] training loss: 0.6557, testing: 283 correct, 0.6675 accuracy
[fold 2 epoch 89] training loss: 0.6254, testing: 283 correct, 0.6675 accuracy
[fold 2 epoch 99] training loss: 0.5560, testing: 287 correct, 0.6769 accuracy
[fold 2 epoch 109] training loss: 0.5355, testing: 281 correct, 0.6627 accuracy
[fold 2 epoch 119] training loss: 0.5095, testing: 279 correct, 0.6580 accuracy
[fold 2 epoch 129] training loss: 0.4718, testing: 274 correct, 0.6462 accuracy
[fold 2 epoch 139] training loss: 0.4586, testing: 283 correct, 0.6675 accuracy
[fold 2 epoch 149] training loss: 0.4505, testing: 285 correct, 0.6722 accuracy
learning rate decay!
Fold 3: 1762 training data, 397 testing data
[fold 3 epoch 9] training loss: 2.8329, testing: 201 correct, 0.5063 accuracy
[fold 3 epoch 19] training loss: 1.8084, testing: 252 correct, 0.6348 accuracy
[fold 3 epoch 29] training loss: 1.4846, testing: 253 correct, 0.6373 accuracy
[fold 3 epoch 39] training loss: 1.2068, testing: 266 correct, 0.6700 accuracy
[fold 3 epoch 49] training loss: 1.0172, testing: 266 correct, 0.6700 accuracy
[fold 3 epoch 59] training loss: 0.8135, testing: 260 correct, 0.6549 accuracy
[fold 3 epoch 69] training loss: 0.7110, testing: 263 correct, 0.6625 accuracy
learning rate decay!
[fold 3 epoch 79] training loss: 0.5675, testing: 266 correct, 0.6700 accuracy
[fold 3 epoch 89] training loss: 0.5848, testing: 267 correct, 0.6725 accuracy
[fold 3 epoch 99] training loss: 0.5313, testing: 264 correct, 0.6650 accuracy
[fold 3 epoch 109] training loss: 0.4764, testing: 271 correct, 0.6826 accuracy
[fold 3 epoch 119] training loss: 0.4465, testing: 272 correct, 0.6851 accuracy
[fold 3 epoch 129] training loss: 0.4333, testing: 267 correct, 0.6725 accuracy
[fold 3 epoch 139] training loss: 0.3960, testing: 267 correct, 0.6725 accuracy
[fold 3 epoch 149] training loss: 0.3650, testing: 268 correct, 0.6751 accuracy
learning rate decay!
Fold 4: 1784 training data, 375 testing data
[fold 4 epoch 9] training loss: 2.9921, testing: 165 correct, 0.4400 accuracy
[fold 4 epoch 19] training loss: 2.0695, testing: 196 correct, 0.5227 accuracy
[fold 4 epoch 29] training loss: 1.6825, testing: 198 correct, 0.5280 accuracy
[fold 4 epoch 39] training loss: 1.3274, testing: 214 correct, 0.5707 accuracy
[fold 4 epoch 49] training loss: 1.1340, testing: 208 correct, 0.5547 accuracy
[fold 4 epoch 59] training loss: 0.9378, testing: 202 correct, 0.5387 accuracy
[fold 4 epoch 69] training loss: 0.8290, testing: 209 correct, 0.5573 accuracy
learning rate decay!
[fold 4 epoch 79] training loss: 0.6736, testing: 212 correct, 0.5653 accuracy
[fold 4 epoch 89] training loss: 0.6402, testing: 212 correct, 0.5653 accuracy
[fold 4 epoch 99] training loss: 0.6113, testing: 209 correct, 0.5573 accuracy
[fold 4 epoch 109] training loss: 0.5398, testing: 214 correct, 0.5707 accuracy
[fold 4 epoch 119] training loss: 0.5093, testing: 216 correct, 0.5760 accuracy
[fold 4 epoch 129] training loss: 0.4819, testing: 214 correct, 0.5707 accuracy
[fold 4 epoch 139] training loss: 0.4591, testing: 207 correct, 0.5520 accuracy
[fold 4 epoch 149] training loss: 0.4083, testing: 204 correct, 0.5440 accuracy
learning rate decay!
finial accuracy: 0.6256


Transformer, fixed pretrain
unfixed pretrain: 0.6679
Max_seq_len = 35
Embedding_size = 200
Hidden_size = 200
Inner_hid_size = 1024
D_k = 64
D_v = 64
Num_layers = 6
Num_head = 8
Learning_rate = 0.0001
Weight_decay = 0.0015
LR_decay = 0.5
Epoch = 500
LR_decay_epoch = 200
Batch_size = 128
1266 different words, 181 different codes
Fold 0: 1655 training data, 504 testing data
[fold 0 epoch 9] training loss: 3.8386, testing: 105 correct, 0.2083 accuracy
[fold 0 epoch 19] training loss: 3.3363, testing: 148 correct, 0.2937 accuracy
[fold 0 epoch 29] training loss: 2.9916, testing: 177 correct, 0.3512 accuracy
[fold 0 epoch 39] training loss: 2.7929, testing: 203 correct, 0.4028 accuracy
[fold 0 epoch 49] training loss: 2.5947, testing: 220 correct, 0.4365 accuracy
[fold 0 epoch 59] training loss: 2.4598, testing: 233 correct, 0.4623 accuracy
[fold 0 epoch 69] training loss: 2.3312, testing: 248 correct, 0.4921 accuracy
[fold 0 epoch 79] training loss: 2.1942, testing: 256 correct, 0.5079 accuracy
[fold 0 epoch 89] training loss: 2.1081, testing: 258 correct, 0.5119 accuracy
[fold 0 epoch 99] training loss: 2.0123, testing: 263 correct, 0.5218 accuracy
[fold 0 epoch 109] training loss: 1.9328, testing: 275 correct, 0.5456 accuracy
[fold 0 epoch 119] training loss: 1.8555, testing: 270 correct, 0.5357 accuracy
[fold 0 epoch 129] training loss: 1.7635, testing: 282 correct, 0.5595 accuracy
[fold 0 epoch 139] training loss: 1.6968, testing: 284 correct, 0.5635 accuracy
[fold 0 epoch 149] training loss: 1.6056, testing: 291 correct, 0.5774 accuracy
[fold 0 epoch 159] training loss: 1.5698, testing: 299 correct, 0.5933 accuracy
[fold 0 epoch 169] training loss: 1.4976, testing: 297 correct, 0.5893 accuracy
[fold 0 epoch 179] training loss: 1.4360, testing: 301 correct, 0.5972 accuracy
[fold 0 epoch 189] training loss: 1.3854, testing: 304 correct, 0.6032 accuracy
[fold 0 epoch 199] training loss: 1.3297, testing: 309 correct, 0.6131 accuracy
learning rate decay!
[fold 0 epoch 209] training loss: 1.2847, testing: 310 correct, 0.6151 accuracy
[fold 0 epoch 219] training loss: 1.2704, testing: 314 correct, 0.6230 accuracy
[fold 0 epoch 229] training loss: 1.2405, testing: 316 correct, 0.6270 accuracy
[fold 0 epoch 239] training loss: 1.2089, testing: 316 correct, 0.6270 accuracy
[fold 0 epoch 249] training loss: 1.1867, testing: 317 correct, 0.6290 accuracy
[fold 0 epoch 259] training loss: 1.1694, testing: 317 correct, 0.6290 accuracy
[fold 0 epoch 269] training loss: 1.1555, testing: 316 correct, 0.6270 accuracy
[fold 0 epoch 279] training loss: 1.1191, testing: 315 correct, 0.6250 accuracy
[fold 0 epoch 289] training loss: 1.1018, testing: 318 correct, 0.6310 accuracy
[fold 0 epoch 299] training loss: 1.0847, testing: 316 correct, 0.6270 accuracy
[fold 0 epoch 309] training loss: 1.0625, testing: 316 correct, 0.6270 accuracy
[fold 0 epoch 319] training loss: 1.0500, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 329] training loss: 1.0301, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 339] training loss: 1.0109, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 349] training loss: 1.0012, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 359] training loss: 0.9775, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 369] training loss: 0.9697, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 379] training loss: 0.9437, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 389] training loss: 0.9315, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 399] training loss: 0.9129, testing: 323 correct, 0.6409 accuracy
learning rate decay!
[fold 0 epoch 409] training loss: 0.8970, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 419] training loss: 0.8956, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 429] training loss: 0.8857, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 439] training loss: 0.8773, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 449] training loss: 0.8699, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 459] training loss: 0.8603, testing: 324 correct, 0.6429 accuracy
[fold 0 epoch 469] training loss: 0.8544, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 479] training loss: 0.8462, testing: 322 correct, 0.6389 accuracy
[fold 0 epoch 489] training loss: 0.8396, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 499] training loss: 0.8387, testing: 324 correct, 0.6429 accuracy
Fold 1: 1700 training data, 459 testing data
[fold 1 epoch 9] training loss: 3.6964, testing: 121 correct, 0.2636 accuracy
[fold 1 epoch 19] training loss: 3.1505, testing: 163 correct, 0.3551 accuracy
[fold 1 epoch 29] training loss: 2.8190, testing: 181 correct, 0.3943 accuracy
[fold 1 epoch 39] training loss: 2.5744, testing: 213 correct, 0.4641 accuracy
[fold 1 epoch 49] training loss: 2.3726, testing: 225 correct, 0.4902 accuracy
[fold 1 epoch 59] training loss: 2.2245, testing: 239 correct, 0.5207 accuracy
[fold 1 epoch 69] training loss: 2.0861, testing: 247 correct, 0.5381 accuracy
[fold 1 epoch 79] training loss: 1.9647, testing: 248 correct, 0.5403 accuracy
[fold 1 epoch 89] training loss: 1.8634, testing: 259 correct, 0.5643 accuracy
[fold 1 epoch 99] training loss: 1.7642, testing: 266 correct, 0.5795 accuracy
[fold 1 epoch 109] training loss: 1.6705, testing: 269 correct, 0.5861 accuracy
[fold 1 epoch 119] training loss: 1.5888, testing: 275 correct, 0.5991 accuracy
[fold 1 epoch 129] training loss: 1.5329, testing: 285 correct, 0.6209 accuracy
[fold 1 epoch 139] training loss: 1.4373, testing: 286 correct, 0.6231 accuracy
[fold 1 epoch 149] training loss: 1.3871, testing: 288 correct, 0.6275 accuracy
[fold 1 epoch 159] training loss: 1.3222, testing: 289 correct, 0.6296 accuracy
[fold 1 epoch 169] training loss: 1.2660, testing: 293 correct, 0.6383 accuracy
[fold 1 epoch 179] training loss: 1.2132, testing: 298 correct, 0.6492 accuracy
[fold 1 epoch 189] training loss: 1.1700, testing: 304 correct, 0.6623 accuracy
[fold 1 epoch 199] training loss: 1.1078, testing: 304 correct, 0.6623 accuracy
learning rate decay!
[fold 1 epoch 209] training loss: 1.0701, testing: 307 correct, 0.6688 accuracy
[fold 1 epoch 219] training loss: 1.0406, testing: 308 correct, 0.6710 accuracy
[fold 1 epoch 229] training loss: 1.0155, testing: 310 correct, 0.6754 accuracy
[fold 1 epoch 239] training loss: 0.9990, testing: 307 correct, 0.6688 accuracy
[fold 1 epoch 249] training loss: 0.9820, testing: 309 correct, 0.6732 accuracy
[fold 1 epoch 259] training loss: 0.9607, testing: 313 correct, 0.6819 accuracy
[fold 1 epoch 269] training loss: 0.9360, testing: 306 correct, 0.6667 accuracy
[fold 1 epoch 279] training loss: 0.9277, testing: 309 correct, 0.6732 accuracy
[fold 1 epoch 289] training loss: 0.9034, testing: 313 correct, 0.6819 accuracy
[fold 1 epoch 299] training loss: 0.8839, testing: 308 correct, 0.6710 accuracy
[fold 1 epoch 309] training loss: 0.8709, testing: 304 correct, 0.6623 accuracy
[fold 1 epoch 319] training loss: 0.8559, testing: 312 correct, 0.6797 accuracy
[fold 1 epoch 329] training loss: 0.8397, testing: 310 correct, 0.6754 accuracy
[fold 1 epoch 339] training loss: 0.8076, testing: 317 correct, 0.6906 accuracy
[fold 1 epoch 349] training loss: 0.8013, testing: 312 correct, 0.6797 accuracy
[fold 1 epoch 359] training loss: 0.7900, testing: 315 correct, 0.6863 accuracy
[fold 1 epoch 369] training loss: 0.7677, testing: 318 correct, 0.6928 accuracy
[fold 1 epoch 379] training loss: 0.7503, testing: 319 correct, 0.6950 accuracy
[fold 1 epoch 389] training loss: 0.7448, testing: 315 correct, 0.6863 accuracy
[fold 1 epoch 399] training loss: 0.7337, testing: 320 correct, 0.6972 accuracy
learning rate decay!
[fold 1 epoch 409] training loss: 0.7139, testing: 323 correct, 0.7037 accuracy
[fold 1 epoch 419] training loss: 0.7101, testing: 325 correct, 0.7081 accuracy
[fold 1 epoch 429] training loss: 0.7033, testing: 324 correct, 0.7059 accuracy
[fold 1 epoch 439] training loss: 0.7046, testing: 321 correct, 0.6993 accuracy
[fold 1 epoch 449] training loss: 0.6885, testing: 324 correct, 0.7059 accuracy
[fold 1 epoch 459] training loss: 0.6869, testing: 327 correct, 0.7124 accuracy
[fold 1 epoch 469] training loss: 0.6805, testing: 325 correct, 0.7081 accuracy
[fold 1 epoch 479] training loss: 0.6650, testing: 324 correct, 0.7059 accuracy
[fold 1 epoch 489] training loss: 0.6675, testing: 325 correct, 0.7081 accuracy
[fold 1 epoch 499] training loss: 0.6609, testing: 323 correct, 0.7037 accuracy
Fold 2: 1735 training data, 424 testing data
[fold 2 epoch 9] training loss: 3.6122, testing: 127 correct, 0.2995 accuracy
[fold 2 epoch 19] training loss: 3.0117, testing: 154 correct, 0.3632 accuracy
[fold 2 epoch 29] training loss: 2.6571, testing: 174 correct, 0.4104 accuracy
[fold 2 epoch 39] training loss: 2.4392, testing: 193 correct, 0.4552 accuracy
[fold 2 epoch 49] training loss: 2.2567, testing: 208 correct, 0.4906 accuracy
[fold 2 epoch 59] training loss: 2.0966, testing: 217 correct, 0.5118 accuracy
[fold 2 epoch 69] training loss: 1.9658, testing: 231 correct, 0.5448 accuracy
[fold 2 epoch 79] training loss: 1.8427, testing: 240 correct, 0.5660 accuracy
[fold 2 epoch 89] training loss: 1.7321, testing: 244 correct, 0.5755 accuracy
[fold 2 epoch 99] training loss: 1.6485, testing: 254 correct, 0.5991 accuracy
[fold 2 epoch 109] training loss: 1.5324, testing: 255 correct, 0.6014 accuracy
[fold 2 epoch 119] training loss: 1.4693, testing: 262 correct, 0.6179 accuracy
[fold 2 epoch 129] training loss: 1.3984, testing: 267 correct, 0.6297 accuracy
[fold 2 epoch 139] training loss: 1.3266, testing: 266 correct, 0.6274 accuracy
[fold 2 epoch 149] training loss: 1.2728, testing: 269 correct, 0.6344 accuracy
[fold 2 epoch 159] training loss: 1.2103, testing: 269 correct, 0.6344 accuracy
[fold 2 epoch 169] training loss: 1.1677, testing: 272 correct, 0.6415 accuracy
[fold 2 epoch 179] training loss: 1.1117, testing: 273 correct, 0.6439 accuracy
[fold 2 epoch 189] training loss: 1.0652, testing: 281 correct, 0.6627 accuracy
[fold 2 epoch 199] training loss: 1.0263, testing: 282 correct, 0.6651 accuracy
learning rate decay!
[fold 2 epoch 209] training loss: 0.9779, testing: 288 correct, 0.6792 accuracy
[fold 2 epoch 219] training loss: 0.9640, testing: 283 correct, 0.6675 accuracy
[fold 2 epoch 229] training loss: 0.9439, testing: 285 correct, 0.6722 accuracy
[fold 2 epoch 239] training loss: 0.9290, testing: 284 correct, 0.6698 accuracy
[fold 2 epoch 249] training loss: 0.9101, testing: 287 correct, 0.6769 accuracy
[fold 2 epoch 259] training loss: 0.8918, testing: 286 correct, 0.6745 accuracy
[fold 2 epoch 269] training loss: 0.8769, testing: 290 correct, 0.6840 accuracy
[fold 2 epoch 279] training loss: 0.8552, testing: 288 correct, 0.6792 accuracy
[fold 2 epoch 289] training loss: 0.8412, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 299] training loss: 0.8202, testing: 291 correct, 0.6863 accuracy
[fold 2 epoch 309] training loss: 0.8101, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 319] training loss: 0.7913, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 329] training loss: 0.7732, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 339] training loss: 0.7610, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 349] training loss: 0.7509, testing: 296 correct, 0.6981 accuracy
[fold 2 epoch 359] training loss: 0.7341, testing: 292 correct, 0.6887 accuracy
[fold 2 epoch 369] training loss: 0.7576, testing: 295 correct, 0.6958 accuracy
[fold 2 epoch 379] training loss: 0.7234, testing: 299 correct, 0.7052 accuracy
[fold 2 epoch 389] training loss: 0.6934, testing: 296 correct, 0.6981 accuracy
[fold 2 epoch 399] training loss: 0.6776, testing: 294 correct, 0.6934 accuracy
learning rate decay!
[fold 2 epoch 409] training loss: 0.6740, testing: 298 correct, 0.7028 accuracy
[fold 2 epoch 419] training loss: 0.6627, testing: 297 correct, 0.7005 accuracy
[fold 2 epoch 429] training loss: 0.6668, testing: 297 correct, 0.7005 accuracy
[fold 2 epoch 439] training loss: 0.6537, testing: 297 correct, 0.7005 accuracy
[fold 2 epoch 449] training loss: 0.6488, testing: 299 correct, 0.7052 accuracy
[fold 2 epoch 459] training loss: 0.6459, testing: 298 correct, 0.7028 accuracy
[fold 2 epoch 469] training loss: 0.6347, testing: 296 correct, 0.6981 accuracy
[fold 2 epoch 479] training loss: 0.6288, testing: 298 correct, 0.7028 accuracy
[fold 2 epoch 489] training loss: 0.6254, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 499] training loss: 0.6171, testing: 295 correct, 0.6958 accuracy
Fold 3: 1762 training data, 397 testing data
[fold 3 epoch 9] training loss: 3.7068, testing: 108 correct, 0.2720 accuracy
[fold 3 epoch 19] training loss: 3.2289, testing: 142 correct, 0.3577 accuracy
[fold 3 epoch 29] training loss: 2.9524, testing: 159 correct, 0.4005 accuracy
[fold 3 epoch 39] training loss: 2.7527, testing: 175 correct, 0.4408 accuracy
[fold 3 epoch 49] training loss: 2.5904, testing: 198 correct, 0.4987 accuracy
[fold 3 epoch 59] training loss: 2.4361, testing: 206 correct, 0.5189 accuracy
[fold 3 epoch 69] training loss: 2.3010, testing: 218 correct, 0.5491 accuracy
[fold 3 epoch 79] training loss: 2.1860, testing: 227 correct, 0.5718 accuracy
[fold 3 epoch 89] training loss: 2.0832, testing: 234 correct, 0.5894 accuracy
[fold 3 epoch 99] training loss: 1.9909, testing: 236 correct, 0.5945 accuracy
[fold 3 epoch 109] training loss: 1.8961, testing: 246 correct, 0.6196 accuracy
[fold 3 epoch 119] training loss: 1.8223, testing: 249 correct, 0.6272 accuracy
[fold 3 epoch 129] training loss: 1.6991, testing: 260 correct, 0.6549 accuracy
[fold 3 epoch 139] training loss: 1.6187, testing: 256 correct, 0.6448 accuracy
[fold 3 epoch 149] training loss: 1.5496, testing: 262 correct, 0.6599 accuracy
[fold 3 epoch 159] training loss: 1.4824, testing: 260 correct, 0.6549 accuracy
[fold 3 epoch 169] training loss: 1.4391, testing: 269 correct, 0.6776 accuracy
[fold 3 epoch 179] training loss: 1.3663, testing: 265 correct, 0.6675 accuracy
[fold 3 epoch 189] training loss: 1.3214, testing: 274 correct, 0.6902 accuracy
[fold 3 epoch 199] training loss: 1.2331, testing: 268 correct, 0.6751 accuracy
learning rate decay!
[fold 3 epoch 209] training loss: 1.2047, testing: 273 correct, 0.6877 accuracy
[fold 3 epoch 219] training loss: 1.1719, testing: 271 correct, 0.6826 accuracy
[fold 3 epoch 229] training loss: 1.1632, testing: 274 correct, 0.6902 accuracy
[fold 3 epoch 239] training loss: 1.1312, testing: 273 correct, 0.6877 accuracy
[fold 3 epoch 249] training loss: 1.1122, testing: 272 correct, 0.6851 accuracy
[fold 3 epoch 259] training loss: 1.0912, testing: 274 correct, 0.6902 accuracy
[fold 3 epoch 269] training loss: 1.0654, testing: 277 correct, 0.6977 accuracy
[fold 3 epoch 279] training loss: 1.0482, testing: 279 correct, 0.7028 accuracy
[fold 3 epoch 289] training loss: 1.0319, testing: 277 correct, 0.6977 accuracy
[fold 3 epoch 299] training loss: 1.0115, testing: 276 correct, 0.6952 accuracy
[fold 3 epoch 309] training loss: 0.9794, testing: 281 correct, 0.7078 accuracy
[fold 3 epoch 319] training loss: 0.9745, testing: 276 correct, 0.6952 accuracy
[fold 3 epoch 329] training loss: 0.9439, testing: 280 correct, 0.7053 accuracy
[fold 3 epoch 339] training loss: 0.9364, testing: 280 correct, 0.7053 accuracy
[fold 3 epoch 349] training loss: 0.9081, testing: 282 correct, 0.7103 accuracy
[fold 3 epoch 359] training loss: 0.9033, testing: 283 correct, 0.7128 accuracy
[fold 3 epoch 369] training loss: 0.8809, testing: 286 correct, 0.7204 accuracy
[fold 3 epoch 379] training loss: 0.8676, testing: 282 correct, 0.7103 accuracy
[fold 3 epoch 389] training loss: 0.8557, testing: 283 correct, 0.7128 accuracy
[fold 3 epoch 399] training loss: 0.8424, testing: 286 correct, 0.7204 accuracy
learning rate decay!
[fold 3 epoch 409] training loss: 0.8202, testing: 285 correct, 0.7179 accuracy
[fold 3 epoch 419] training loss: 0.8144, testing: 284 correct, 0.7154 accuracy
[fold 3 epoch 429] training loss: 0.8059, testing: 287 correct, 0.7229 accuracy
[fold 3 epoch 439] training loss: 0.8034, testing: 287 correct, 0.7229 accuracy
[fold 3 epoch 449] training loss: 0.7967, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 459] training loss: 0.7882, testing: 285 correct, 0.7179 accuracy
[fold 3 epoch 469] training loss: 0.7780, testing: 286 correct, 0.7204 accuracy
[fold 3 epoch 479] training loss: 0.7755, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 489] training loss: 0.7651, testing: 288 correct, 0.7254 accuracy
[fold 3 epoch 499] training loss: 0.7524, testing: 291 correct, 0.7330 accuracy
Fold 4: 1784 training data, 375 testing data
[fold 4 epoch 9] training loss: 3.6546, testing: 54 correct, 0.1440 accuracy
[fold 4 epoch 19] training loss: 3.1849, testing: 95 correct, 0.2533 accuracy
[fold 4 epoch 29] training loss: 2.8638, testing: 106 correct, 0.2827 accuracy
[fold 4 epoch 39] training loss: 2.6569, testing: 117 correct, 0.3120 accuracy
[fold 4 epoch 49] training loss: 2.4920, testing: 127 correct, 0.3387 accuracy
[fold 4 epoch 59] training loss: 2.3602, testing: 139 correct, 0.3707 accuracy
[fold 4 epoch 69] training loss: 2.2329, testing: 138 correct, 0.3680 accuracy
[fold 4 epoch 79] training loss: 2.1229, testing: 154 correct, 0.4107 accuracy
[fold 4 epoch 89] training loss: 2.0212, testing: 181 correct, 0.4827 accuracy
[fold 4 epoch 99] training loss: 1.9285, testing: 195 correct, 0.5200 accuracy
[fold 4 epoch 109] training loss: 1.8489, testing: 203 correct, 0.5413 accuracy
[fold 4 epoch 119] training loss: 1.7635, testing: 211 correct, 0.5627 accuracy
[fold 4 epoch 129] training loss: 1.6996, testing: 214 correct, 0.5707 accuracy
[fold 4 epoch 139] training loss: 1.6375, testing: 216 correct, 0.5760 accuracy
[fold 4 epoch 149] training loss: 1.5685, testing: 223 correct, 0.5947 accuracy
[fold 4 epoch 159] training loss: 1.5107, testing: 229 correct, 0.6107 accuracy
[fold 4 epoch 169] training loss: 1.4556, testing: 228 correct, 0.6080 accuracy
[fold 4 epoch 179] training loss: 1.3933, testing: 240 correct, 0.6400 accuracy
[fold 4 epoch 189] training loss: 1.3383, testing: 241 correct, 0.6427 accuracy
[fold 4 epoch 199] training loss: 1.2758, testing: 237 correct, 0.6320 accuracy
learning rate decay!
[fold 4 epoch 209] training loss: 1.2355, testing: 240 correct, 0.6400 accuracy
[fold 4 epoch 219] training loss: 1.2158, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 229] training loss: 1.1855, testing: 245 correct, 0.6533 accuracy
[fold 4 epoch 239] training loss: 1.1729, testing: 246 correct, 0.6560 accuracy
[fold 4 epoch 249] training loss: 1.1422, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 259] training loss: 1.1258, testing: 245 correct, 0.6533 accuracy
[fold 4 epoch 269] training loss: 1.1018, testing: 248 correct, 0.6613 accuracy
[fold 4 epoch 279] training loss: 1.0824, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 289] training loss: 1.0654, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 299] training loss: 1.0477, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 309] training loss: 1.0250, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 319] training loss: 1.0083, testing: 255 correct, 0.6800 accuracy
[fold 4 epoch 329] training loss: 0.9917, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 339] training loss: 0.9714, testing: 254 correct, 0.6773 accuracy
[fold 4 epoch 349] training loss: 0.9563, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 359] training loss: 0.9323, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 369] training loss: 0.9243, testing: 250 correct, 0.6667 accuracy
[fold 4 epoch 379] training loss: 0.9008, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 389] training loss: 0.8847, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 399] training loss: 0.8656, testing: 251 correct, 0.6693 accuracy
learning rate decay!
[fold 4 epoch 409] training loss: 0.8550, testing: 250 correct, 0.6667 accuracy
[fold 4 epoch 419] training loss: 0.8471, testing: 250 correct, 0.6667 accuracy
[fold 4 epoch 429] training loss: 0.8348, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 439] training loss: 0.8324, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 449] training loss: 0.8229, testing: 254 correct, 0.6773 accuracy
[fold 4 epoch 459] training loss: 0.8225, testing: 256 correct, 0.6827 accuracy
[fold 4 epoch 469] training loss: 0.8049, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 479] training loss: 0.7994, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 489] training loss: 0.7948, testing: 255 correct, 0.6800 accuracy
[fold 4 epoch 499] training loss: 0.7897, testing: 254 correct, 0.6773 accuracy
finial accuracy: 0.6905

with embedding dropout
Max_seq_len = 35
Embedding_size = 200
Hidden_size = 200
Inner_hid_size = 1024
D_k = 64
D_v = 64
Num_layers = 6
Num_head = 5
Learning_rate = 0.0001
Weight_decay = 0.0015
LR_decay = 0.5
Epoch = 600
LR_decay_epoch = 200
Batch_size = 128
1266 different words, 181 different codes
Fold 0: 1655 training data, 504 testing data
[fold 0 epoch 9] training loss: 4.0143, testing: 118 correct, 0.2341 accuracy
[fold 0 epoch 19] training loss: 3.5308, testing: 159 correct, 0.3155 accuracy
[fold 0 epoch 29] training loss: 3.2569, testing: 185 correct, 0.3671 accuracy
[fold 0 epoch 39] training loss: 3.0172, testing: 189 correct, 0.3750 accuracy
[fold 0 epoch 49] training loss: 2.8442, testing: 206 correct, 0.4087 accuracy
[fold 0 epoch 59] training loss: 2.6606, testing: 220 correct, 0.4365 accuracy
[fold 0 epoch 69] training loss: 2.5401, testing: 232 correct, 0.4603 accuracy
[fold 0 epoch 79] training loss: 2.4319, testing: 236 correct, 0.4683 accuracy
[fold 0 epoch 89] training loss: 2.3203, testing: 246 correct, 0.4881 accuracy
[fold 0 epoch 99] training loss: 2.1971, testing: 250 correct, 0.4960 accuracy
[fold 0 epoch 109] training loss: 2.1044, testing: 255 correct, 0.5060 accuracy
[fold 0 epoch 119] training loss: 2.0304, testing: 265 correct, 0.5258 accuracy
[fold 0 epoch 129] training loss: 1.9586, testing: 273 correct, 0.5417 accuracy
[fold 0 epoch 139] training loss: 1.8675, testing: 277 correct, 0.5496 accuracy
[fold 0 epoch 149] training loss: 1.7956, testing: 282 correct, 0.5595 accuracy
[fold 0 epoch 159] training loss: 1.7243, testing: 285 correct, 0.5655 accuracy
[fold 0 epoch 169] training loss: 1.6506, testing: 297 correct, 0.5893 accuracy
[fold 0 epoch 179] training loss: 1.6025, testing: 293 correct, 0.5813 accuracy
[fold 0 epoch 189] training loss: 1.5380, testing: 302 correct, 0.5992 accuracy
[fold 0 epoch 199] training loss: 1.4958, testing: 300 correct, 0.5952 accuracy
learning rate decay!
[fold 0 epoch 209] training loss: 1.4616, testing: 304 correct, 0.6032 accuracy
[fold 0 epoch 219] training loss: 1.4159, testing: 304 correct, 0.6032 accuracy
[fold 0 epoch 229] training loss: 1.3911, testing: 308 correct, 0.6111 accuracy
[fold 0 epoch 239] training loss: 1.3596, testing: 309 correct, 0.6131 accuracy
[fold 0 epoch 249] training loss: 1.3275, testing: 315 correct, 0.6250 accuracy
[fold 0 epoch 259] training loss: 1.3223, testing: 315 correct, 0.6250 accuracy
[fold 0 epoch 269] training loss: 1.2924, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 279] training loss: 1.2694, testing: 315 correct, 0.6250 accuracy
[fold 0 epoch 289] training loss: 1.2511, testing: 317 correct, 0.6290 accuracy
[fold 0 epoch 299] training loss: 1.2416, testing: 320 correct, 0.6349 accuracy
[fold 0 epoch 309] training loss: 1.2170, testing: 318 correct, 0.6310 accuracy
[fold 0 epoch 319] training loss: 1.2007, testing: 319 correct, 0.6329 accuracy
[fold 0 epoch 329] training loss: 1.1632, testing: 321 correct, 0.6369 accuracy
[fold 0 epoch 339] training loss: 1.1333, testing: 325 correct, 0.6448 accuracy
[fold 0 epoch 349] training loss: 1.1365, testing: 328 correct, 0.6508 accuracy
[fold 0 epoch 359] training loss: 1.1293, testing: 324 correct, 0.6429 accuracy
[fold 0 epoch 369] training loss: 1.0834, testing: 325 correct, 0.6448 accuracy
[fold 0 epoch 379] training loss: 1.0829, testing: 323 correct, 0.6409 accuracy
[fold 0 epoch 389] training loss: 1.0535, testing: 325 correct, 0.6448 accuracy
[fold 0 epoch 399] training loss: 1.0488, testing: 324 correct, 0.6429 accuracy
learning rate decay!
[fold 0 epoch 409] training loss: 1.0270, testing: 328 correct, 0.6508 accuracy
[fold 0 epoch 419] training loss: 1.0383, testing: 331 correct, 0.6567 accuracy
[fold 0 epoch 429] training loss: 1.0184, testing: 329 correct, 0.6528 accuracy
[fold 0 epoch 439] training loss: 1.0032, testing: 327 correct, 0.6488 accuracy
[fold 0 epoch 449] training loss: 1.0036, testing: 328 correct, 0.6508 accuracy
[fold 0 epoch 459] training loss: 0.9780, testing: 329 correct, 0.6528 accuracy
[fold 0 epoch 469] training loss: 0.9781, testing: 332 correct, 0.6587 accuracy
[fold 0 epoch 479] training loss: 0.9707, testing: 327 correct, 0.6488 accuracy
[fold 0 epoch 489] training loss: 0.9557, testing: 329 correct, 0.6528 accuracy
[fold 0 epoch 499] training loss: 0.9508, testing: 330 correct, 0.6548 accuracy
[fold 0 epoch 509] training loss: 0.9406, testing: 326 correct, 0.6468 accuracy
[fold 0 epoch 519] training loss: 0.9542, testing: 327 correct, 0.6488 accuracy
[fold 0 epoch 529] training loss: 0.9337, testing: 333 correct, 0.6607 accuracy
[fold 0 epoch 539] training loss: 0.9291, testing: 330 correct, 0.6548 accuracy
[fold 0 epoch 549] training loss: 0.9359, testing: 327 correct, 0.6488 accuracy
[fold 0 epoch 559] training loss: 0.9013, testing: 328 correct, 0.6508 accuracy
[fold 0 epoch 569] training loss: 0.9052, testing: 333 correct, 0.6607 accuracy
[fold 0 epoch 579] training loss: 0.8916, testing: 331 correct, 0.6567 accuracy
[fold 0 epoch 589] training loss: 0.8867, testing: 332 correct, 0.6587 accuracy
[fold 0 epoch 599] training loss: 0.8903, testing: 334 correct, 0.6627 accuracy
learning rate decay!
Fold 1: 1700 training data, 459 testing data
[fold 1 epoch 9] training loss: 3.8602, testing: 121 correct, 0.2636 accuracy
[fold 1 epoch 19] training loss: 3.2954, testing: 162 correct, 0.3529 accuracy
[fold 1 epoch 29] training loss: 2.9505, testing: 182 correct, 0.3965 accuracy
[fold 1 epoch 39] training loss: 2.6537, testing: 205 correct, 0.4466 accuracy
[fold 1 epoch 49] training loss: 2.4658, testing: 220 correct, 0.4793 accuracy
[fold 1 epoch 59] training loss: 2.3644, testing: 227 correct, 0.4946 accuracy
[fold 1 epoch 69] training loss: 2.1574, testing: 238 correct, 0.5185 accuracy
[fold 1 epoch 79] training loss: 2.0767, testing: 242 correct, 0.5272 accuracy
[fold 1 epoch 89] training loss: 1.9713, testing: 250 correct, 0.5447 accuracy
[fold 1 epoch 99] training loss: 1.8725, testing: 262 correct, 0.5708 accuracy
[fold 1 epoch 109] training loss: 1.8126, testing: 275 correct, 0.5991 accuracy
[fold 1 epoch 119] training loss: 1.7499, testing: 279 correct, 0.6078 accuracy
[fold 1 epoch 129] training loss: 1.6839, testing: 281 correct, 0.6122 accuracy
[fold 1 epoch 139] training loss: 1.5820, testing: 282 correct, 0.6144 accuracy
[fold 1 epoch 149] training loss: 1.5199, testing: 289 correct, 0.6296 accuracy
[fold 1 epoch 159] training loss: 1.4384, testing: 297 correct, 0.6471 accuracy
[fold 1 epoch 169] training loss: 1.3795, testing: 302 correct, 0.6580 accuracy
[fold 1 epoch 179] training loss: 1.3193, testing: 305 correct, 0.6645 accuracy
[fold 1 epoch 189] training loss: 1.2693, testing: 299 correct, 0.6514 accuracy
[fold 1 epoch 199] training loss: 1.2013, testing: 311 correct, 0.6776 accuracy
learning rate decay!
[fold 1 epoch 209] training loss: 1.1578, testing: 313 correct, 0.6819 accuracy
[fold 1 epoch 219] training loss: 1.1372, testing: 317 correct, 0.6906 accuracy
[fold 1 epoch 229] training loss: 1.1036, testing: 316 correct, 0.6885 accuracy
[fold 1 epoch 239] training loss: 1.0861, testing: 318 correct, 0.6928 accuracy
[fold 1 epoch 249] training loss: 1.0750, testing: 322 correct, 0.7015 accuracy
[fold 1 epoch 259] training loss: 1.0545, testing: 323 correct, 0.7037 accuracy
[fold 1 epoch 269] training loss: 1.0205, testing: 325 correct, 0.7081 accuracy
[fold 1 epoch 279] training loss: 1.0184, testing: 328 correct, 0.7146 accuracy
[fold 1 epoch 289] training loss: 0.9862, testing: 325 correct, 0.7081 accuracy
[fold 1 epoch 299] training loss: 0.9650, testing: 327 correct, 0.7124 accuracy
[fold 1 epoch 309] training loss: 0.9538, testing: 328 correct, 0.7146 accuracy
[fold 1 epoch 319] training loss: 0.9133, testing: 330 correct, 0.7190 accuracy
[fold 1 epoch 329] training loss: 0.8906, testing: 326 correct, 0.7102 accuracy
[fold 1 epoch 339] training loss: 0.8793, testing: 331 correct, 0.7211 accuracy
[fold 1 epoch 349] training loss: 0.8632, testing: 329 correct, 0.7168 accuracy
[fold 1 epoch 359] training loss: 0.8505, testing: 331 correct, 0.7211 accuracy
[fold 1 epoch 369] training loss: 0.8296, testing: 336 correct, 0.7320 accuracy
[fold 1 epoch 379] training loss: 0.8234, testing: 330 correct, 0.7190 accuracy
[fold 1 epoch 389] training loss: 0.8042, testing: 337 correct, 0.7342 accuracy
[fold 1 epoch 399] training loss: 0.7661, testing: 337 correct, 0.7342 accuracy
learning rate decay!
[fold 1 epoch 409] training loss: 0.7600, testing: 338 correct, 0.7364 accuracy
[fold 1 epoch 419] training loss: 0.7427, testing: 337 correct, 0.7342 accuracy
[fold 1 epoch 429] training loss: 0.7443, testing: 337 correct, 0.7342 accuracy
[fold 1 epoch 439] training loss: 0.7290, testing: 335 correct, 0.7298 accuracy
[fold 1 epoch 449] training loss: 0.7211, testing: 338 correct, 0.7364 accuracy
[fold 1 epoch 459] training loss: 0.7232, testing: 340 correct, 0.7407 accuracy
[fold 1 epoch 469] training loss: 0.7170, testing: 338 correct, 0.7364 accuracy
[fold 1 epoch 479] training loss: 0.7077, testing: 337 correct, 0.7342 accuracy
[fold 1 epoch 489] training loss: 0.6956, testing: 339 correct, 0.7386 accuracy
[fold 1 epoch 499] training loss: 0.6779, testing: 339 correct, 0.7386 accuracy
[fold 1 epoch 509] training loss: 0.6796, testing: 338 correct, 0.7364 accuracy
[fold 1 epoch 519] training loss: 0.6850, testing: 340 correct, 0.7407 accuracy
[fold 1 epoch 529] training loss: 0.6737, testing: 335 correct, 0.7298 accuracy
[fold 1 epoch 539] training loss: 0.6637, testing: 337 correct, 0.7342 accuracy
[fold 1 epoch 549] training loss: 0.6499, testing: 339 correct, 0.7386 accuracy
[fold 1 epoch 559] training loss: 0.6430, testing: 336 correct, 0.7320 accuracy
[fold 1 epoch 569] training loss: 0.6434, testing: 339 correct, 0.7386 accuracy
[fold 1 epoch 579] training loss: 0.6188, testing: 339 correct, 0.7386 accuracy
[fold 1 epoch 589] training loss: 0.6386, testing: 341 correct, 0.7429 accuracy
[fold 1 epoch 599] training loss: 0.6262, testing: 336 correct, 0.7320 accuracy
learning rate decay!
Fold 2: 1735 training data, 424 testing data
[fold 2 epoch 9] training loss: 4.0238, testing: 86 correct, 0.2028 accuracy
[fold 2 epoch 19] training loss: 3.4156, testing: 131 correct, 0.3090 accuracy
[fold 2 epoch 29] training loss: 3.0382, testing: 158 correct, 0.3726 accuracy
[fold 2 epoch 39] training loss: 2.7506, testing: 178 correct, 0.4198 accuracy
[fold 2 epoch 49] training loss: 2.5530, testing: 199 correct, 0.4693 accuracy
[fold 2 epoch 59] training loss: 2.4186, testing: 212 correct, 0.5000 accuracy
[fold 2 epoch 69] training loss: 2.2573, testing: 217 correct, 0.5118 accuracy
[fold 2 epoch 79] training loss: 2.1276, testing: 231 correct, 0.5448 accuracy
[fold 2 epoch 89] training loss: 2.0616, testing: 244 correct, 0.5755 accuracy
[fold 2 epoch 99] training loss: 1.9370, testing: 242 correct, 0.5708 accuracy
[fold 2 epoch 109] training loss: 1.8280, testing: 255 correct, 0.6014 accuracy
[fold 2 epoch 119] training loss: 1.7277, testing: 265 correct, 0.6250 accuracy
[fold 2 epoch 129] training loss: 1.6424, testing: 273 correct, 0.6439 accuracy
[fold 2 epoch 139] training loss: 1.5443, testing: 280 correct, 0.6604 accuracy
[fold 2 epoch 149] training loss: 1.4863, testing: 277 correct, 0.6533 accuracy
[fold 2 epoch 159] training loss: 1.4215, testing: 282 correct, 0.6651 accuracy
[fold 2 epoch 169] training loss: 1.3426, testing: 282 correct, 0.6651 accuracy
[fold 2 epoch 179] training loss: 1.3027, testing: 284 correct, 0.6698 accuracy
[fold 2 epoch 189] training loss: 1.2346, testing: 285 correct, 0.6722 accuracy
[fold 2 epoch 199] training loss: 1.2004, testing: 286 correct, 0.6745 accuracy
learning rate decay!
[fold 2 epoch 209] training loss: 1.1441, testing: 295 correct, 0.6958 accuracy
[fold 2 epoch 219] training loss: 1.1192, testing: 295 correct, 0.6958 accuracy
[fold 2 epoch 229] training loss: 1.0857, testing: 294 correct, 0.6934 accuracy
[fold 2 epoch 239] training loss: 1.0745, testing: 295 correct, 0.6958 accuracy
[fold 2 epoch 249] training loss: 1.0460, testing: 293 correct, 0.6910 accuracy
[fold 2 epoch 259] training loss: 1.0081, testing: 297 correct, 0.7005 accuracy
[fold 2 epoch 269] training loss: 1.0112, testing: 299 correct, 0.7052 accuracy
[fold 2 epoch 279] training loss: 0.9833, testing: 299 correct, 0.7052 accuracy
[fold 2 epoch 289] training loss: 0.9506, testing: 299 correct, 0.7052 accuracy
[fold 2 epoch 299] training loss: 0.9332, testing: 301 correct, 0.7099 accuracy
[fold 2 epoch 309] training loss: 0.9168, testing: 304 correct, 0.7170 accuracy
[fold 2 epoch 319] training loss: 0.9145, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 329] training loss: 0.8865, testing: 304 correct, 0.7170 accuracy
[fold 2 epoch 339] training loss: 0.8821, testing: 303 correct, 0.7146 accuracy
[fold 2 epoch 349] training loss: 0.8490, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 359] training loss: 0.8268, testing: 305 correct, 0.7193 accuracy
[fold 2 epoch 369] training loss: 0.8134, testing: 307 correct, 0.7241 accuracy
[fold 2 epoch 379] training loss: 0.8136, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 389] training loss: 0.7843, testing: 309 correct, 0.7288 accuracy
[fold 2 epoch 399] training loss: 0.7897, testing: 306 correct, 0.7217 accuracy
learning rate decay!
[fold 2 epoch 409] training loss: 0.7472, testing: 305 correct, 0.7193 accuracy
[fold 2 epoch 419] training loss: 0.7522, testing: 307 correct, 0.7241 accuracy
[fold 2 epoch 429] training loss: 0.7341, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 439] training loss: 0.7248, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 449] training loss: 0.7300, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 459] training loss: 0.7230, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 469] training loss: 0.7235, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 479] training loss: 0.6945, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 489] training loss: 0.7094, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 499] training loss: 0.6902, testing: 309 correct, 0.7288 accuracy
[fold 2 epoch 509] training loss: 0.6969, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 519] training loss: 0.6796, testing: 307 correct, 0.7241 accuracy
[fold 2 epoch 529] training loss: 0.6744, testing: 308 correct, 0.7264 accuracy
[fold 2 epoch 539] training loss: 0.6746, testing: 309 correct, 0.7288 accuracy
[fold 2 epoch 549] training loss: 0.6868, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 559] training loss: 0.6491, testing: 310 correct, 0.7311 accuracy
[fold 2 epoch 569] training loss: 0.6473, testing: 309 correct, 0.7288 accuracy
[fold 2 epoch 579] training loss: 0.6315, testing: 309 correct, 0.7288 accuracy
[fold 2 epoch 589] training loss: 0.6243, testing: 307 correct, 0.7241 accuracy
[fold 2 epoch 599] training loss: 0.6200, testing: 310 correct, 0.7311 accuracy
learning rate decay!
Fold 3: 1762 training data, 397 testing data
[fold 3 epoch 9] training loss: 3.8708, testing: 92 correct, 0.2317 accuracy
[fold 3 epoch 19] training loss: 3.3648, testing: 133 correct, 0.3350 accuracy
[fold 3 epoch 29] training loss: 3.0179, testing: 161 correct, 0.4055 accuracy
[fold 3 epoch 39] training loss: 2.7183, testing: 178 correct, 0.4484 accuracy
[fold 3 epoch 49] training loss: 2.5058, testing: 190 correct, 0.4786 accuracy
[fold 3 epoch 59] training loss: 2.3280, testing: 200 correct, 0.5038 accuracy
[fold 3 epoch 69] training loss: 2.1605, testing: 211 correct, 0.5315 accuracy
[fold 3 epoch 79] training loss: 2.0463, testing: 217 correct, 0.5466 accuracy
[fold 3 epoch 89] training loss: 1.9086, testing: 228 correct, 0.5743 accuracy
[fold 3 epoch 99] training loss: 1.8314, testing: 237 correct, 0.5970 accuracy
[fold 3 epoch 109] training loss: 1.7328, testing: 244 correct, 0.6146 accuracy
[fold 3 epoch 119] training loss: 1.6632, testing: 257 correct, 0.6474 accuracy
[fold 3 epoch 129] training loss: 1.5589, testing: 260 correct, 0.6549 accuracy
[fold 3 epoch 139] training loss: 1.4818, testing: 267 correct, 0.6725 accuracy
[fold 3 epoch 149] training loss: 1.4245, testing: 269 correct, 0.6776 accuracy
[fold 3 epoch 159] training loss: 1.3579, testing: 269 correct, 0.6776 accuracy
[fold 3 epoch 169] training loss: 1.2951, testing: 274 correct, 0.6902 accuracy
[fold 3 epoch 179] training loss: 1.2488, testing: 279 correct, 0.7028 accuracy
[fold 3 epoch 189] training loss: 1.1921, testing: 281 correct, 0.7078 accuracy
[fold 3 epoch 199] training loss: 1.1701, testing: 284 correct, 0.7154 accuracy
learning rate decay!
[fold 3 epoch 209] training loss: 1.1333, testing: 285 correct, 0.7179 accuracy
[fold 3 epoch 219] training loss: 1.0788, testing: 283 correct, 0.7128 accuracy
[fold 3 epoch 229] training loss: 1.0793, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 239] training loss: 1.0426, testing: 282 correct, 0.7103 accuracy
[fold 3 epoch 249] training loss: 1.0698, testing: 288 correct, 0.7254 accuracy
[fold 3 epoch 259] training loss: 1.0492, testing: 286 correct, 0.7204 accuracy
[fold 3 epoch 269] training loss: 1.0049, testing: 283 correct, 0.7128 accuracy
[fold 3 epoch 279] training loss: 0.9779, testing: 287 correct, 0.7229 accuracy
[fold 3 epoch 289] training loss: 0.9764, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 299] training loss: 0.9419, testing: 290 correct, 0.7305 accuracy
[fold 3 epoch 309] training loss: 0.9140, testing: 289 correct, 0.7280 accuracy
[fold 3 epoch 319] training loss: 0.9264, testing: 293 correct, 0.7380 accuracy
[fold 3 epoch 329] training loss: 0.8830, testing: 287 correct, 0.7229 accuracy
[fold 3 epoch 339] training loss: 0.8840, testing: 294 correct, 0.7406 accuracy
[fold 3 epoch 349] training loss: 0.8763, testing: 290 correct, 0.7305 accuracy
[fold 3 epoch 359] training loss: 0.8377, testing: 286 correct, 0.7204 accuracy
[fold 3 epoch 369] training loss: 0.8413, testing: 292 correct, 0.7355 accuracy
[fold 3 epoch 379] training loss: 0.8183, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 389] training loss: 0.8069, testing: 293 correct, 0.7380 accuracy
[fold 3 epoch 399] training loss: 0.7857, testing: 296 correct, 0.7456 accuracy
learning rate decay!
[fold 3 epoch 409] training loss: 0.7653, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 419] training loss: 0.7678, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 429] training loss: 0.7589, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 439] training loss: 0.7575, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 449] training loss: 0.7509, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 459] training loss: 0.7578, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 469] training loss: 0.7386, testing: 297 correct, 0.7481 accuracy
[fold 3 epoch 479] training loss: 0.7189, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 489] training loss: 0.7118, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 499] training loss: 0.7293, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 509] training loss: 0.7138, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 519] training loss: 0.7011, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 529] training loss: 0.6902, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 539] training loss: 0.6965, testing: 296 correct, 0.7456 accuracy
[fold 3 epoch 549] training loss: 0.7043, testing: 298 correct, 0.7506 accuracy
[fold 3 epoch 559] training loss: 0.6993, testing: 298 correct, 0.7506 accuracy
[fold 3 epoch 569] training loss: 0.6724, testing: 295 correct, 0.7431 accuracy
[fold 3 epoch 579] training loss: 0.6681, testing: 297 correct, 0.7481 accuracy
[fold 3 epoch 589] training loss: 0.6640, testing: 298 correct, 0.7506 accuracy
[fold 3 epoch 599] training loss: 0.6601, testing: 297 correct, 0.7481 accuracy
learning rate decay!
Fold 4: 1784 training data, 375 testing data
[fold 4 epoch 9] training loss: 4.1380, testing: 56 correct, 0.1493 accuracy
[fold 4 epoch 19] training loss: 3.5727, testing: 112 correct, 0.2987 accuracy
[fold 4 epoch 29] training loss: 3.2736, testing: 132 correct, 0.3520 accuracy
[fold 4 epoch 39] training loss: 3.0096, testing: 147 correct, 0.3920 accuracy
[fold 4 epoch 49] training loss: 2.8304, testing: 164 correct, 0.4373 accuracy
[fold 4 epoch 59] training loss: 2.6647, testing: 174 correct, 0.4640 accuracy
[fold 4 epoch 69] training loss: 2.5189, testing: 179 correct, 0.4773 accuracy
[fold 4 epoch 79] training loss: 2.3693, testing: 188 correct, 0.5013 accuracy
[fold 4 epoch 89] training loss: 2.2620, testing: 206 correct, 0.5493 accuracy
[fold 4 epoch 99] training loss: 2.1167, testing: 202 correct, 0.5387 accuracy
[fold 4 epoch 109] training loss: 2.0474, testing: 213 correct, 0.5680 accuracy
[fold 4 epoch 119] training loss: 1.9825, testing: 212 correct, 0.5653 accuracy
[fold 4 epoch 129] training loss: 1.8555, testing: 219 correct, 0.5840 accuracy
[fold 4 epoch 139] training loss: 1.7895, testing: 222 correct, 0.5920 accuracy
[fold 4 epoch 149] training loss: 1.7115, testing: 226 correct, 0.6027 accuracy
[fold 4 epoch 159] training loss: 1.6430, testing: 233 correct, 0.6213 accuracy
[fold 4 epoch 169] training loss: 1.5834, testing: 235 correct, 0.6267 accuracy
[fold 4 epoch 179] training loss: 1.5105, testing: 236 correct, 0.6293 accuracy
[fold 4 epoch 189] training loss: 1.4455, testing: 240 correct, 0.6400 accuracy
[fold 4 epoch 199] training loss: 1.3753, testing: 245 correct, 0.6533 accuracy
learning rate decay!
[fold 4 epoch 209] training loss: 1.3392, testing: 237 correct, 0.6320 accuracy
[fold 4 epoch 219] training loss: 1.2993, testing: 244 correct, 0.6507 accuracy
[fold 4 epoch 229] training loss: 1.2901, testing: 242 correct, 0.6453 accuracy
[fold 4 epoch 239] training loss: 1.2296, testing: 245 correct, 0.6533 accuracy
[fold 4 epoch 249] training loss: 1.2143, testing: 246 correct, 0.6560 accuracy
[fold 4 epoch 259] training loss: 1.2054, testing: 245 correct, 0.6533 accuracy
[fold 4 epoch 269] training loss: 1.1804, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 279] training loss: 1.1517, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 289] training loss: 1.1321, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 299] training loss: 1.1300, testing: 247 correct, 0.6587 accuracy
[fold 4 epoch 309] training loss: 1.0756, testing: 248 correct, 0.6613 accuracy
[fold 4 epoch 319] training loss: 1.0564, testing: 246 correct, 0.6560 accuracy
[fold 4 epoch 329] training loss: 1.0680, testing: 250 correct, 0.6667 accuracy
[fold 4 epoch 339] training loss: 1.0280, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 349] training loss: 1.0012, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 359] training loss: 0.9600, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 369] training loss: 0.9539, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 379] training loss: 0.9549, testing: 246 correct, 0.6560 accuracy
[fold 4 epoch 389] training loss: 0.9250, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 399] training loss: 0.9229, testing: 249 correct, 0.6640 accuracy
learning rate decay!
[fold 4 epoch 409] training loss: 0.8954, testing: 248 correct, 0.6613 accuracy
[fold 4 epoch 419] training loss: 0.8762, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 429] training loss: 0.8931, testing: 248 correct, 0.6613 accuracy
[fold 4 epoch 439] training loss: 0.8642, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 449] training loss: 0.8654, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 459] training loss: 0.8870, testing: 253 correct, 0.6747 accuracy
[fold 4 epoch 469] training loss: 0.8362, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 479] training loss: 0.8282, testing: 250 correct, 0.6667 accuracy
[fold 4 epoch 489] training loss: 0.8338, testing: 250 correct, 0.6667 accuracy
[fold 4 epoch 499] training loss: 0.8256, testing: 247 correct, 0.6587 accuracy
[fold 4 epoch 509] training loss: 0.8008, testing: 247 correct, 0.6587 accuracy
[fold 4 epoch 519] training loss: 0.8027, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 529] training loss: 0.8043, testing: 247 correct, 0.6587 accuracy
[fold 4 epoch 539] training loss: 0.7823, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 549] training loss: 0.7796, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 559] training loss: 0.7688, testing: 249 correct, 0.6640 accuracy
[fold 4 epoch 569] training loss: 0.7578, testing: 251 correct, 0.6693 accuracy
[fold 4 epoch 579] training loss: 0.7641, testing: 248 correct, 0.6613 accuracy
[fold 4 epoch 589] training loss: 0.7399, testing: 252 correct, 0.6720 accuracy
[fold 4 epoch 599] training loss: 0.7401, testing: 252 correct, 0.6720 accuracy
learning rate decay!
finial accuracy: 0.7092
